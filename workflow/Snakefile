
from scripts.workflow_utils import get_samples, get_min_quality, vibrant_virome

SAMPLE, FRAC = get_samples(config["path"]["input"])

onstart:
    touch(config["path"]["temp"])
    touch(config["path"]["log"])
    print("Samples: " + ", ".join(SAMPLE))


onsuccess:
    print("Workflow finished successfully!")


onerror:
    print("Error has occured. Please, check log files for more details.")


module qc:
    snakefile:
        "rules/qc.smk"
    config:
        config

module assembly:
	snakefile:
		"rules/assembly.smk"
	config:
		config

module identification:
	snakefile:
		"rules/identification.smk"
	config:
		config

use rule * from qc
use rule * from assembly
use rule * from identification



# addition of rule to create master expand command for the different viral identifier
# functionalizes the ASSEMBLY rule for the different viral identifers, to be done
# def get_output_dirs(pipeline: str) -> list:

rule ALL:
    input:
        config["path"]["temp"] + "/finished_QC",
        config["path"]["temp"] + "/finished_ASSEMBLY",
        config["path"]["temp"] + "/finished_IDENTIFICATION",
        config["path"]["temp"] + "/finished_MAPPING",
        config["path"]["temp"] + "/finished_TAXONOMY",
        config["path"]["temp"] + "/finished_FUNCTION",
        config["path"]["temp"] + "/finished_STATS",
    params:
        temp=config["path"]["temp"],
    threads: 1
    resources:
        mem_mb=config["memory"]["small"],
        runtime=config["time"]["tiny"],
    shell:
        """
        rm -rdf {params.temp}
        """

# MAPPING


rule MAPPING:
    input:
        config["path"]["output"] + "/mapping/index",
        expand(
            config["path"]["output"] + "/mapping/BAM/{sample}.map.bam",
            sample=SAMPLE,
        ),
        expand(
            config["path"]["output"]
            + "/contig_stats/{sample}/postfilter_base_coverage.txt.gz",
            sample=SAMPLE,
        ),
        expand(
            config["path"]["output"]
            + "/contig_stats/{sample}/postfilter_coverage_histogram.txt",
            sample=SAMPLE,
        ),
        expand(
            config["path"]["output"]
            + "/contig_stats/{sample}/postfilter_coverage_stats.txt",
            sample=SAMPLE,
        ),
        expand(
            config["path"]["output"]
            + "/contig_stats/{sample}/postfilter_coverage_binned.txt",
            sample=SAMPLE,
        ),
        expand(
            config["path"]["output"]
            + "/contig_stats/{sample}/trimmed_mean_coverage.tsv",
            sample=SAMPLE,
        ),
        config["path"]["output"] + "/contig_stats/raw_coverage_table.tsv",
        expand(
            config["path"]["output"] + "/instrain/{sample}",
            sample=SAMPLE,
        ),
        config["path"]["output"] + "/instrain/compared_samples",
    output:
        config["path"]["temp"] + "/finished_MAPPING",
    threads: 1
    resources:
        mem_mb=config["memory"]["small"],
        runtime=config["time"]["tiny"],
    message:
        "[MAPPING] Mapping finished..."
    shell:
        """
        touch {output}
        """


rule build_index:
    """
    Builds an index to prepare for mapping
    """
    input:
        rules.transform_vOTUs.output.vOTU,
    output:
        index_dir=directory(config["path"]["output"] + "/mapping/index"),
    conda:
        config["path"]["envs"] + "/bowtie2.yaml"
    message:
        "[build_index] Building index for mapping..."
    benchmark:
        config["path"]["benchmark"] + "/build_index.txt"
    log:
        config["path"]["log"] + "/bowtie2_build_index.log",
    threads: config["threads"]
    resources:
        mem_mb=config["memory"]["small"],
        runtime=config["time"]["tiny"],
    shell:
        """
        mkdir -p {output.index_dir}
        bowtie2-build {input} {output.index_dir}/mapping_index &> {log}
        """


rule read_mapping:
    """
    performs read mapping between original sample and vOTUs
    """
    input:
        R1=rules.fastp_pe.output.R1,
        R2=rules.fastp_pe.output.R2,
        index_dir=rules.build_index.output.index_dir,
    output:
        config["path"]["output"] + "/mapping/BAM/{sample}.map.bam",
    conda:
        config["path"]["envs"] + "/bowtie2.yaml"
    log:
        bowtie2=config["path"]["log"] + "/bowtie2_mapping/{sample}.log",
        samtools=config["path"]["log"] + "/sam_to_bam/{sample}.log",
    benchmark:
        config["path"]["benchmark"] + "/bowtie2_mapping/{sample}.txt"
    threads: config["threads"]
    resources:
        mem_mb=config["memory"]["small"],
        runtime=config["time"]["tiny"],
    shell:
        """
        bowtie2 -p {threads} -x {input.index_dir}/mapping_index \
        -1 {input.R1} -2 {input.R2} 2> {log.bowtie2} | \
        samtools view -b -o {output} - &> {log.samtools}
        """

rule contig_stats:
    """
    Creates simple coverage statisitcs for each read mapping
    """
    input:
        genomes=config["path"]["output"] + "/vOTU/vOTU_derep95_combined.fasta",
        bam=rules.read_mapping.output,
    output:
        basecov=config["path"]["output"]
        + "/contig_stats/{sample}/postfilter_base_coverage.txt.gz",
        covhist=config["path"]["output"]
        + "/contig_stats/{sample}/postfilter_coverage_histogram.txt",
        covstats=config["path"]["output"]
        + "/contig_stats/{sample}/postfilter_coverage_stats.txt",
        bincov=config["path"]["output"]
        + "/contig_stats/{sample}/postfilter_coverage_binned.txt",
    conda:
        config["path"]["envs"] + "/bowtie2.yaml"
    log:
        config["path"]["log"] + "/contig_stats/{sample}.log",
    benchmark:
        config["path"]["benchmark"] + "/contig_stats/{sample}.txt"
    message:
        "[contig_stats] Creating coverage statistics for each sample..."
    threads: config["threads"]
    resources:
        mem_mb=config["memory"]["small"],
        runtime=config["time"]["tiny"],
    shell:
        """
        pileup.sh ref={input.genomes} in={input.bam} \
            threads={threads} \
            -Xmx{resources.mem_mb}m \
            covstats={output.covstats} \
            hist={output.covhist} \
            basecov={output.basecov} \
            concise=t \
            secondary=t \
            bincov={output.bincov} &> {log}
        """


rule get_trimmed_coverage:
    """
    Gets the trimmed mean of the coverage
    """
    input:
        basecov=rules.contig_stats.output.basecov,
        covstats=rules.contig_stats.output.covstats,
    output:
        trimmed_mean=config["path"]["output"]
        + "/contig_stats/{sample}/trimmed_mean_coverage.tsv",
    params:
        trim_perc=config["trim_percentage"],
    threads: 1
    resources:
        mem_mb=config["memory"]["small"],
        runtime=config["time"]["tiny"],
    log:
        config["path"]["log"] + "/trimmed_mean/{sample}.log",
    benchmark:
        config["path"]["benchmark"] + "/trimmed_mean/{sample}.txt"
    message:
        "[get_trimmed_coverage] Getting trimmed mean of coverage..."
    script:
        config["path"]["scripts"] + "/trimmed_mean.py"


rule combine_coverage:
    """
    Combines all the coverages into one file,
    prepeares for making the relative abundance
    """
    input:
        covstats=expand(
            config["path"]["output"]
            + "/contig_stats/{sample}/postfilter_coverage_stats.txt",
            sample=SAMPLE,
        ),
    output:
        abundance_table=config["path"]["output"]
        + "/contig_stats/raw_coverage_table.tsv",
    params:
        min_coverage=config["min_coverage"],
    threads: 1
    resources:
        mem_mb=config["memory"]["small"],
        runtime=config["time"]["tiny"],
    conda:
        config["path"]["envs"] + "/tidyverse.yaml"
    message:
        "[combine_coverage] Combining coverage statistics..."
    script:
        config["path"]["scripts"] + "/combine_coverage.R"


rule instrain_profile:
    """
    Create inStrain profiles
    """
    input:
        genome=rules.transform_vOTUs.output.vOTU,
        mapping=rules.read_mapping.output,
    output:
        directory(config["path"]["output"] + "/instrain/{sample}/"),
    conda:
        config["path"]["envs"] + "/instrain.yaml"
    log:
        config["path"]["log"] + "/instrain/{sample}.log",
    benchmark:
        config["path"]["benchmark"] + "/instrain/{sample}.txt"
    message:
        "[instrain_profile] Creating inStrain profiles..."
    threads: config["threads"]
    resources:
        mem_mb=config["memory"]["big"],
        runtime=config["time"]["normal"],
    shell:
        """
        inStrain profile {input.mapping} {input.genome} -o {output} &> {log}
        """


rule instrain_compare:
    """
    Compare inStrain profiles
    """
    input:
        expand(
            config["path"]["output"] + "/instrain/{sample}/",
            sample=SAMPLE,
        ),
    output:
        directory(config["path"]["output"] + "/instrain/compared_samples"),
    conda:
        config["path"]["envs"] + "/instrain.yaml"
    log:
        config["path"]["log"] + "/instrain/compare.log",
    benchmark:
        config["path"]["benchmark"] + "/instrain/compare.txt"
    message:
        "[instrain_compare] Comparing inStrain profiles..."
    threads: config["threads"]
    resources:
        mem_mb=config["memory"]["big"],
        runtime=config["time"]["normal"],
    shell:
        """
        inStrain compare -i {input} -o {output} &> {log}
        """


# TAXONOMIC ANALYSIS


rule TAXONOMY:
    input:
        config["path"]["output"] + "/prodigal/proteins.faa",
        config["path"]["output"] + "/prodigal/ORFs.genes",
        config["path"]["output"] + "/vcontact2/genes_2_genomes/g2g.csv",
        config["path"]["output"]
        + "/vcontact2/genes_2_genomes/viral_genomes_combined.csv",
        config["path"]["output"] + "/vcontact2/genes_2_genomes/combined_proteins.faa",
        config["path"]["output"] + "/vcontact2/taxonomic_annotation/",
    output:
        config["path"]["temp"] + "/finished_TAXONOMY",
    threads: 1
    resources:
        mem_mb=config["memory"]["small"],
        runtime=config["time"]["tiny"],
    shell:
        """
        touch {output}
        """


rule prodigal:
    """
    performs gene prediction on vOTUs
    """
    input:
        rules.transform_vOTUs.output.vOTU,
    output:
        proteins=config["path"]["output"] + "/prodigal/proteins.faa",
        orf=config["path"]["output"] + "/prodigal/ORFs.genes",
    conda:
        config["path"]["envs"] + "/prodigal.yaml"
    log:
        config["path"]["log"] + "/prodigal.log",
    benchmark:
        config["path"]["benchmark"] + "/prodigal.txt"
    threads: config["threads"]
    message:
        "[prodigal] Predicting genes..."
    resources:
        mem_mb=config["memory"]["small"],
        runtime=config["time"]["tiny"],
    shell:
        """
        prodigal -i {input} -o {output.proteins} -a {output.orf} -p meta\
        &> {log}
        """


rule gene2genome:
    """
    performs gene2genome setup for VCONTACT2
    """
    input:
        rules.prodigal.output.orf,
    output:
        config["path"]["output"] + "/vcontact2/genes_2_genomes/g2g.csv",
    conda:
        config["path"]["envs"] + "/vcontact2.yaml"
    log:
        config["path"]["log"] + "/vcontact2_gene2genome.log",
    benchmark:
        config["path"]["benchmark"] + "/vcontact2_gene2genome.txt"
    message:
        "[vcontact2_gene2genome] Setting up gene2genome..."
    resources:
        mem_mb=config["memory"]["small"],
        runtime=config["time"]["tiny"],
    threads: config["threads"]
    shell:
        """
        vcontact2_gene2genome -p {input} -o {output} -s 'Prodigal-FAA'\
        &> {log}
        """


rule inphared_setup:
    """
    Adds relevant entires from INPHARED into setup files before VCONTACT2
    """
    params:
        inphared_g2g=config["path"]["database"]["INPHARED"]
        + "/vConTACT2_gene_to_genome.csv",
        inphared_proteins=config["path"]["database"]["INPHARED"]
        + "/vConTACT2_proteins.faa",
        simplify_faa=config["path"]["scripts"] + "/simplify_faa-ffn_derep.py",
    input:
        g2g=rules.gene2genome.output,
        proteins=rules.prodigal.output.proteins,
        orf=rules.prodigal.output.orf,
    output:
        combinedg2g=config["path"]["output"]
        + "/vcontact2/genes_2_genomes/viral_genomes_combined.csv",
        combined_proteins=config["path"]["output"]
        + "/vcontact2/genes_2_genomes/combined_proteins.faa",
    benchmark:
        config["path"]["benchmark"] + "/inphared_setup.txt"
    log:
        config["path"]["log"] + "/inphared_setup.log",
    conda:
        config["path"]["envs"] + "/vibrant.yaml"
    resources:
        mem_mb=config["memory"]["small"],
        runtime=config["time"]["tiny"],
    threads: config["threads"]
    shell:
        """
        cat {input.g2g} {params.inphared_g2g} > {output.combinedg2g}
        sed -i 's/,None_provided/,none/g' {output.combinedg2g}
        python3 {params.simplify_faa} {input.orf}
        cat {input.orf}.simple.faa {params.inphared_proteins} > {output.combined_proteins}
        """


rule vcontact2:
    """
    Performs Taxonomic annotation with VCONTACT2
    """
    input:
        proteins=config["path"]["output"]
        + "/vcontact2/genes_2_genomes/combined_proteins.faa",
        g2g=config["path"]["output"]
        + "/vcontact2/genes_2_genomes/viral_genomes_combined.csv",
    output:
        dir=directory(config["path"]["output"] + "/vcontact2/taxonomic_annotation/"),
    benchmark:
        config["path"]["benchmark"] + "/vcontact2.txt"
    conda:
        config["path"]["envs"] + "/vcontact2.yaml"
    log:
        config["path"]["log"] + "/vcontact2.log",
    resources:
        mem_mb=config["memory"]["vcontact2"],
        runtime=config["time"]["vcontact2"],
    threads: config["threads"]
    shell:
        """
        rm -rdf {output.dir}/combined*
        vcontact2 -t {threads} \
            --raw-proteins {input.proteins} \
            --rel-mode 'Diamond' \
            --proteins-fp {input.g2g} \
            --db 'None' \
            --pcs-mode MCL \
            --vcs-mode ClusterONE \
            --output-dir {output.dir} \
            &> {log}
        """


rule graphanalyzer:
    """
    Performs the post-processing of VCONTACT2 results
    automatically
    """
    params:
        graph=config["path"]["scripts"] + "/graphanalyzer.py",
        meta=config["path"]["database"]["INPHARED"] + "/data_excluding_refseq.tsv",
    input:
        rules.vcontact2.output.dir,
    output:
        dir=directory(config["path"]["output"] + "/graphanalyzer/"),
        vOTU_results=config["path"]["output"]
        + "/graphanalyzer/csv_edit_vOTU_results.xlsx",
    conda:
        config["path"]["envs"] + "/graphanalyzer.yaml"
    threads: config["threads"]
    resources:
        mem_mb=config["memory"]["normal"],
        runtime=config["time"]["normal"],
    log:
        config["path"]["log"] + "/graphanalyzer.log",
    benchmark:
        config["path"]["benchmark"] + "/graphanalyzer.txt"
    shell:
        """
        python3 {params.graph}\
        --graph {input}/c1.ntw\
        --csv {input}/genome_by_genome_overview.csv\
        --metas {params.meta}\
        --output {output.dir}/\
        --prefix vOTU\
        --suffix vOTU_results\
        --threads {threads}\
        &> {log}
        # cat {output.vOTU_results}
        """



# FUNCTIONAL ANALYSIS


rule FUNCTION:
    input:
        config["path"]["output"] + "/DRAMv/annotations/",
        config["path"]["output"] + "/DRAMv/distilled/",
        config["path"]["output"] + "/DRAMv/distilled/amg_summary.tsv",
        config["path"]["output"] + "/graphanalyzer/",
        config["path"]["output"] + "/graphanalyzer/csv_edit_vOTU_results.xlsx",
    output:
        config["path"]["temp"] + "/finished_FUNCTION",
    threads: 1
    resources:
        mem_mb=config["memory"]["small"],
        runtime=config["time"]["tiny"],
    shell:
        """
        touch {output}
        """


rule dramv_annotate:
    """
    Performs Functional annotation with DRAMv
    """
    input:
        rules.virsorter2_pass2.output.dir,
    output:
        dir=directory(config["path"]["output"] + "/DRAMv/annotations/"),
    params:
        DRAM_config=config["path"]["database"]["DRAM"] + "/DRAM.config",
        min_contig_size=config["min_contig_size"],
    conda:
        config["path"]["envs"] + "/DRAMv.yaml"
    log:
        config["path"]["log"] + "/DRAMv.log",
    benchmark:
        config["path"]["benchmark"] + "/DRAMv.txt"
    resources:
        mem_mb=config["memory"]["big"],
        runtime=config["time"]["big"],
    threads: config["threads"]
    shell:
        """
        DRAM-setup.py import_config --config_loc {params.DRAM_config}
        rm -rdf {output.dir}
        DRAM-v.py annotate -i {input}/for-dramv/final-viral-combined-for-dramv.fa\
        -v {input}/for-dramv/viral-affi-contigs-for-dramv.tab\
        --output_dir {output.dir}\
        --threads {threads}\
        --min_contig_size {params.min_contig_size}\
        &> {log}
        """


rule dramv_distill:
    """
    Performs the distillation of functional annotation
    """
    input:
        rules.dramv_annotate.output.dir,
    output:
        dir=directory(config["path"]["output"] + "/DRAMv/distilled/"),
        amg_summary=config["path"]["output"] + "/DRAMv/distilled/amg_summary.tsv",
    log:
        config["path"]["log"] + "/DRAMv_distill.log",
    benchmark:
        config["path"]["benchmark"] + "/DRAMv_distill.txt"
    conda:
        config["path"]["envs"] + "/DRAMv.yaml"
    resources:
        mem_mb=config["memory"]["normal"],
        runtime=config["time"]["normal"],
    shell:
        """
        rm -rd {output.dir}
        DRAM-v.py distill -i {input}/annotations.tsv\
        --output_dir {output.dir}\
        &> {log}
        cat {output.amg_summary}
        """


# STATISTICS

rule STATS:
    input:
#        config["path"]["output"] + "/statistics/Sample_stats_vibrant.tsv",
        config["path"]["output"] + "/statistics/Sample_stats_virsorter2.tsv",
        config["path"]["output"] + "/statistics/vOTU_AMGs.tsv",
        config["path"]["output"] + "/statistics/",
        config["path"]["temp"] + "/html_files.txt",
        config["path"]["temp"] + "/tables.txt",
        config["path"]["output"] + "/complete_output.zip",
        config["path"]["output"] + "/statistics/compared_samples_comparisonsTable.tsv",
        # config["path"]["benchmark"] + "/_summary/",
        # config["path"]["benchmark"] + "/_summary/merged_benchmarks.csv",
        # config["path"]["benchmark"] + "/_summary/REPORT.txt",
        # config["path"]["benchmark"] + "/_summary/plots",
    output:
        config["path"]["temp"] + "/finished_STATS",
    threads: 1
    resources:
        mem_mb=config["memory"]["small"],
        runtime=config["time"]["tiny"],
    shell:
        """
        touch {output}
        """

rule get_stats:
    """
    Performs the aggregation of all relevant files into summaries tables and plots
    """
    input:
        vOTU_results=rules.graphanalyzer.output.vOTU_results,
        amg_summary=rules.dramv_distill.output.amg_summary,
        virsorter2_summary=rules.checkv_vOTU_virsorter2.output.summary,
        transposed_report=rules.metaQUAST.output.transposed_report,
        abundance_table=rules.combine_coverage.output.abundance_table,
    output:
        config["path"]["output"] + "/statistics/compared_samples_comparisonsTable.tsv",
#        config["path"]["output"] + "/statistics/Sample_stats_vibrant.tsv",
        config["path"]["output"] + "/statistics/Sample_stats_virsorter2.tsv",
        config["path"]["output"] + "/statistics/vOTU_AMGs.tsv",
        dir=directory(config["path"]["output"] + "/statistics/"),
    params:
        samples=SAMPLE,
        output_path=config["path"]["output"],
    log:
        config["path"]["log"] + "/get_stats.log",
    benchmark:
        config["path"]["benchmark"] + "/get_stats.txt"
    threads: config["threads"]
    resources:
        mem_mb=config["memory"]["normal"],
        runtime=config["time"]["normal"],
    script:
        config["path"]["scripts"] + "/table_stats.py"

rule find_reports:
    """
    Finds all html files in the output directory
    """
    input:
        config["path"]["temp"] + "/finished_QC",
        config["path"]["temp"] + "/finished_ASSEMBLY",
        config["path"]["temp"] + "/finished_IDENTIFICATION",
        config["path"]["temp"] + "/finished_MAPPING",
        config["path"]["temp"] + "/finished_TAXONOMY",
        config["path"]["temp"] + "/finished_FUNCTION",
    output:
        config["path"]["temp"] + "/html_files.txt",
    params:
        all_output_path=config["path"]["output"],
    threads: 1
    resources:
        mem_mb=config["memory"]["small"],
        runtime=config["time"]["tiny"],
    shell:
        """
        find {params.all_output_path} -name *.html > {output}
        find {params.all_output_path} -name *.pdf >> {output}
        """


rule find_tables:
    input:
        config["path"]["temp"] + "/finished_QC",
        config["path"]["temp"] + "/finished_ASSEMBLY",
        config["path"]["temp"] + "/finished_IDENTIFICATION",
        config["path"]["temp"] + "/finished_MAPPING",
        config["path"]["temp"] + "/finished_TAXONOMY",
        config["path"]["temp"] + "/finished_FUNCTION",
    output:
        config["path"]["temp"] + "/tables.txt",
    params:
        table_list=config["include_tables"],
        all_output_path=config["path"]["output"],
    resources:
        mem_mb=config["memory"]["small"],
        runtime=config["time"]["tiny"],
    shell:
        """
        rm -f {output}
        for table in {params.table_list}; do
            find {params.all_output_path} -name $table >> {output}
        done
        """


rule zip_output:
    """
    Copies all html files to the statistics directory
    """
    input:
        reports=rules.find_reports.output,
        tables=rules.find_tables.output,
    output:
        config["path"]["output"] + "/complete_output.zip",
    params:
        temp=config["path"]["temp"],
    threads: 1
    resources:
        mem_mb=config["memory"]["small"],
        runtime=config["time"]["tiny"],
    script:
        config["path"]["scripts"] + "/zip_output.py"


# rule gather_benchmarks:
#     input:
#         config["path"]["benchmark"],
#     output:
#         dir=directory(config["path"]["benchmark"] + "/_summary/"),
#         merged=config["path"]["benchmark"] + "/_summary/merged_benchmarks.csv",
#         report=config["path"]["benchmark"] + "/_summary/REPORT.txt",
#     threads: 1
#     resources:
#         mem_mb=config["memory"]["small"],
#         runtime=config["time"]["tiny"],
#     script:
#         config["path"]["scripts"] + "/gather_benchmarks.py"
# rule create_benchmark_plots:
#     input:
#         rules.gather_benchmarks.output.merged,
#     output:
#         directory(config["path"]["benchmark"] + "/_summary/plots"),
#     threads: 1
#     resources:
#         mem_mb=config["memory"]["small"],
#         runtime=config["time"]["tiny"],
#     script:
#         config["path"]["scripts"] + "/create_benchmark_plots.R"

#    """
#    Copies all html files to the statistics directory
#   """
#    input:
#        reports=rules.find_reports.output,
#        tables=rules.find_tables.output,
#    output:
#        config["path"]["output"] + "/complete_output.zip",
#    params:
#        temp=config["path"]["temp"],
#    threads: 1
#    resources:
#        mem_mb=config["memory"]["small"],
#        runtime=config["time"]["tiny"],
#    script:
#        config["path"]["scripts"] + "/zip_output.py"
